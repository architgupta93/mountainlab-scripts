{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ms4_franklab_pyplines as pyp\n",
    "import pyff_utils as pyff\n",
    "import ms4_franklab_proc2py as p2p\n",
    "import sys, os, subprocess\n",
    "import logging\n",
    "from distutils.dir_util import copy_tree\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anim details. for now, assume that sort should include all eps/day\n",
    "mda_util_path = '/home/anna/Src/MLpackages/franklab_MS4/mda_util.py'\n",
    "ntlinks_path = '/home/anna/Src/MLpackages/franklab_MS4/MS4setup_NTlinks.node.js'\n",
    "data_dir = '/mnt/vortex/data1_backup/anna/'\n",
    "results_dir='/media/anna/whirlwindtemp1/'\n",
    "anim = 'gus'\n",
    "days = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "dates = [20171022, 20171023, 20171024, 20171025,20171026, 20171027, 20171028, 20171029, 20171030,20171031, \n",
    "           20171101, 20171102, 20171103, 20171104, 20171105, 20171106, 20171107,20171108, 20171109, 20171110] #dates 10/22-11/30\n",
    "\n",
    "# if datelist not provided, fetch dates from taskinfo struct\n",
    "# TODO make py_evaluate filter more flexible so that it can do this\n",
    "\n",
    "#if not dates or len(days)!=len(dates):\n",
    "#    dates = pyff.py_evaluatefilter(base_dir, anim, 'taskinfo', days,['date','*'])\n",
    "\n",
    "#if tetlist not provided, fetch ca1 tets from tetinfo struct\n",
    "tetfilt = ['area','ca1']\n",
    "tetlist = []\n",
    "if not tetlist and tetfilt:\n",
    "    tetlist = pyff.py_evaluatefilter(results_dir, anim, 'tetinfo', days,tetfilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing day 1\n",
      "copying mountain dir to results dir\n",
      "RUNNING: ml-run-process ephys.bandpass_filter --inputs timeseries:/media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/raw.mda --parameters freq_max:6000 freq_min:300 samplerate:30000 --outputs timeseries_out:/media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/filt.mda.prv\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Process ephys.bandpass_filter already completed. ]\u001b[0m\n",
      "\u001b[34m[ Creating output prv for timeseries_out ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n",
      "RUNNING: ml-run-process ms3.mask_out_artifacts --inputs timeseries:/media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/filt.mda.prv --parameters interval_size:2000 threshold:5 --outputs timeseries_out:/media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/filt.mda.prv\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34mLocating /media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/filt.mda.prv ...\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Process ms3.mask_out_artifacts already completed. ]\u001b[0m\n",
      "\u001b[34m[ Creating output prv for timeseries_out ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n",
      "RUNNING: ml-run-process ephys.whiten --inputs timeseries:/media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/filt.mda.prv --parameters --outputs timeseries_out:/media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/pre.mda.prv\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34mLocating /media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/filt.mda.prv ...\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Process ephys.whiten already completed. ]\u001b[0m\n",
      "\u001b[34m[ Creating output prv for timeseries_out ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n",
      "Segment 1: t1=0, t2=47461992, t1_min=0.0, t2_min=26.367773333333332\n",
      "RUNNING: ml-run-process pyms.extract_timeseries --inputs timeseries:/media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/pre.mda.prv --parameters t1:0 t2:47461992 --outputs timeseries_out:/media/anna/whirlwindtemp1/gus/preprocessing/20171022/20171022_gus.mountain/nt1/pre-1.mda\n"
     ]
    }
   ],
   "source": [
    "for index, day in enumerate(days):\n",
    "\n",
    "    day_src_dir = data_dir+anim+'/preprocessing/'+str(dates[index])+'/'\n",
    "    # check if mnt directory exists for this day. if not, call mda_util to generate the symlinks to the mda files\n",
    "    # run this in the data src directory (vortex)\n",
    "    mnt_path = day_src_dir+str(dates[index])+'_'+anim+'.mnt/'\n",
    "    print('processing day '+str(day))\n",
    "    if not os.path.exists(mnt_path):\n",
    "        print('no mnt directory found; calling mda_util')\n",
    "        os.chdir(data_dir+anim+'/preprocessing')\n",
    "        subprocess.call(['python',mda_util_path])  \n",
    "    \n",
    "    # check if .mountain dir exists for this day (still in the data src  dir)\n",
    "    # if not, run the setup javascript to generate prvs that link mda files (via their symlinks) across epochs\n",
    "    # need to generate mountaindir in src then copy it over to results\n",
    "    mountain_src_path = day_src_dir+str(dates[index])+'_'+anim+'.mountain'\n",
    "    mountain_res_path = results_dir+anim+'/preprocessing/'+str(dates[index])+'/'+str(dates[index])+'_'+anim+'.mountain'\n",
    "    if not os.path.exists(mountain_src_path):\n",
    "        print('no mountain dir found; calling setup_NTlinks')\n",
    "        os.chdir(day_src_dir)\n",
    "        subprocess.call([ntlinks_path, mnt_path])\n",
    "    if not os.path.exists(mountain_res_path):\n",
    "        print('copying mountain dir to results dir')\n",
    "        copy_tree(mountain_src_path,mountain_res_path)\n",
    "    \n",
    "    #now for the actually processing: iterate through ntrodes\n",
    "    for nt_ind, nt in enumerate(tetlist[day]):\n",
    "        nt_src_dir = mountain_src_path+'/nt'+str(nt)\n",
    "        nt_out_dir = mountain_res_path+'/nt'+str(nt)\n",
    "        \n",
    "        # concatenate all eps, since ms4 no longer takes a list of mdas; save as raw.mda\n",
    "        # save this to the output dir; it serves as src for subsequent steps\n",
    "        prv_list=nt_src_dir+'/raw.mda.prv'\n",
    "        pyp.concat_eps(dataset_dir=nt_out_dir,mda_list=prv_list)\n",
    "        \n",
    "        # preprocessing: filter, mask out artifacts, whiten\n",
    "        # TODO make optional whether you save the interediates (filt, pre)\n",
    "        pyp.filt_mask_whiten(dataset_dir=nt_out_dir,output_dir=nt_out_dir, freq_min=300,freq_max=6000, opts={})\n",
    "        \n",
    "        #run the actual sort \n",
    "        pyp.ms4_sort_on_segs(dataset_dir=nt_out_dir,output_dir=nt_out_dir, adjacency_radius=-1,detect_threshold=3, detect_sign=-1, opts={})\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a separate loop, go back and add tags to the metrics - due to bug in ms3.combine_cluster_metrics\n",
    "for index, day in enumerate(days):\n",
    "    for nt_ind, nt in enumerate(tetlist[day]):\n",
    "        nt_dir = mountain_path+'/nt'+str(nt)\n",
    "        pyp.add_curation_tags(dataset_dir=nt_dir,output_dir=nt_dir,opts={})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate marks \n",
    "for index, day in enumerate(days):\n",
    "    for nt_ind, nt in enumerate(tetlist[day]):\n",
    "        nt_dir = mountain_path+'/nt'+str(nt)\n",
    "        pyp.extract_marks(dataset_dir=nt_dir,output_dir=nt_dir,opts={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement logging system to track all calls and params used "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
